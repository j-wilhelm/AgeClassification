{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSiTNCJKUAcM",
        "colab_type": "text"
      },
      "source": [
        "# 0. Set-up\n",
        "Mount Google Drive, import packages and import data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJIfepdvUFGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YezQKQr8Xc7v",
        "colab_type": "text"
      },
      "source": [
        "## Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8es67nUUUGrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from keras.layers import ZeroPadding2D, Convolution2D,Activation\n",
        "from keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.utils import np_utils\n",
        "import pickle\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, MaxPooling2D, Conv2D, Flatten, Dropout, Input\n",
        "from keras import *\n",
        "from keras.optimizers import *\n",
        "from keras import metrics\n",
        "from keras.callbacks import *\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import h5py # to save best models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPH6M4PRVtSb",
        "colab_type": "text"
      },
      "source": [
        "## Functions to get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0zVDy55UVjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def get_images(path,max_folders = 1000):\n",
        "  '''Loops through folders to get the images.\n",
        "  path: the path to the main folder in which subfolders containing images are located\n",
        "  max_folders: the maximum number of folders to load (necessary as RAM can't handle everything)\n",
        "  '''\n",
        "  images = []\n",
        "  IDs = []\n",
        "  x = 0\n",
        "  for foldername in tqdm(os.listdir(path)):\n",
        "    if x > max_folders:\n",
        "      break\n",
        "    x += 1\n",
        "    if os.path.isdir(os.path.join(path,foldername)):\n",
        "      for filename in os.listdir(os.path.join(path,foldername)):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "          img = load_img(os.path.join(path,foldername,filename),target_size = (224,224))\n",
        "          img_ID = os.path.basename(filename)[22:]\n",
        "          img = img_to_array(img)\n",
        "          img = img.reshape((1,img.shape[0],img.shape[1],img.shape[2]))\n",
        "          img = img/255\n",
        "\n",
        "          images.append(img)\n",
        "          IDs.append(img_ID)\n",
        "  return(images,IDs)\n",
        "\n",
        "def get_data(path,max_folders,age_dict,val_split,vgg_processing):\n",
        "  '''path: the path leading to the data\n",
        "  max_folders: how many folders to get\n",
        "  age_dict: dictionary which keeps the age group for a certain image ID\n",
        "  val_split: how many images to keep for validation\n",
        "  vgg_processing: whether to preprocess for vgg_16'''\n",
        "\n",
        "  images, IDs = get_images(path,max_folders,vgg_processing)\n",
        "  _y = []\n",
        "  imgs = []\n",
        "  image_ids = []\n",
        "  x = 0\n",
        "  for i in IDs:\n",
        "    try:\n",
        "      value = age_dict[i]\n",
        "      _y.append(value)\n",
        "      imgs.append(images[x])\n",
        "      image_ids.append(i)\n",
        "      x += 1\n",
        "    except KeyError:\n",
        "      x += 1\n",
        "  # shuffle\n",
        "  tmp = list(zip(_y,imgs,image_ids))\n",
        "  random.shuffle(tmp)\n",
        "  \n",
        "  _y, imgs,image_ids = zip(*tmp)\n",
        "  print(type(imgs))\n",
        "  train_x = np.concatenate(imgs[:round(len(imgs)*(1-val_split))],axis = 0)\n",
        "  print(type(train_x))\n",
        "  print(train_x.shape)\n",
        "  train_y = _y[:round(len(imgs)*(1-val_split))]\n",
        "  \n",
        "  train_y = utils.np_utils.to_categorical(train_y)\n",
        "  \n",
        "  val_x = np.concatenate(imgs[round(len(imgs)*(1-val_split)):], axis = 0)\n",
        "  val_y = _y[round(len(imgs)*(1-val_split)):]\n",
        "  \n",
        "  return(train_x,train_y,val_x,val_y,image_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDq_fFZRVxD_",
        "colab_type": "text"
      },
      "source": [
        "## Functions to get image labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVM_M3OnV5HH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Define a binary label for each image ID\n",
        "def older_than_21(a_df,image_column,age_column):\n",
        "  '''Parameters:\n",
        "  a_df: a dataframe from which the data is taken\n",
        "  image_column: index indicating which column the image IDs are in\n",
        "  age_column: index indicating which columns the ages are in'''\n",
        "  a_dict = {}\n",
        "  for index, i in a_df.iterrows():\n",
        "    if any(ages == i[age_column] for ages in['(4, 6)', '(0, 2)', '(8, 13)', '(15, 20)']):\n",
        "        image_id = i[image_column]\n",
        "        a_dict[image_id] = 0\n",
        "    elif any(ages == i[age_column] for ages in ['(25, 32)','(38, 43)','(48, 53)','(60, 100)']):\n",
        "        image_id = i[image_column]\n",
        "        a_dict[image_id] = 1\n",
        "        \n",
        "\n",
        "  return(a_dict)\n",
        "\n",
        "# Get the metadata on all images\n",
        "def get_text(path):\n",
        "  test = True # Can't come up with something more elegant; used to load and store first file as it can't be appended to something empty\n",
        "  for filename in os.listdir(path):\n",
        "    if filename.endswith(\".txt\"):\n",
        "      if test:\n",
        "        file = pd.read_csv(os.path.join(path,filename),sep = '\\t')\n",
        "        test = False\n",
        "      else:\n",
        "        file_tmp = pd.read_csv(os.path.join(path,filename), sep = '\\t')\n",
        "        file = file.append(file_tmp)\n",
        "  # get actual ID\n",
        "  \n",
        "  file['ID'] = file['face_id'].astype(str) + '.' + file['original_image']\n",
        "  \n",
        "  return(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIK28N7TZCNk",
        "colab_type": "text"
      },
      "source": [
        "# 1. Preprocess and store data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgGK-p1wWUvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the text files\n",
        "text_files = get_text('gdrive/My Drive/data/aligned/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H58VEh3eWvLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_files['complete_id'] = text_files['face_id'].astype(str) + '.' + text_files['original_image']\n",
        "text_files.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYzzM_wRWyan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_files['age'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DdLNpvcWzWT",
        "colab_type": "text"
      },
      "source": [
        "Shows the different labels; we will use the top 8 in this study.\n",
        "\n",
        "Now we recode these labels into a binary variable of older/young than 21."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLlWwUTeXAEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "age_group_dict = {}\n",
        "for index, i in text_files.iterrows():\n",
        "  image_ID = i[12]\n",
        "  age_group = i[3]\n",
        "  age_group_dict[image_ID] = age_group\n",
        "  \n",
        "age_dict = older_than_21(text_files,12,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPxaRXR0_cpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Also make a dictionary containing only images in the range 18-30 years old:\n",
        "IDs_18_32 = text_files[(text_files['age'] == '(25, 32)') | (text_files['age'] == '(15, 20)')]\n",
        "IDs_18_32.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbvi1tDpAoeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a dictionary which only contains images from people between 18 and 32 years of age, and label these as older/younger\n",
        "\n",
        "age_dict_18_32 = {}\n",
        "for index, i in IDs_18_32.iterrows():\n",
        "  if i[3] == '(25, 32)':\n",
        "    Older = 1\n",
        "  else:\n",
        "    Older = 0\n",
        "  age_dict_18_32[i[12]] = Older"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZCBba-DAoNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we load images from the files, but only if they exist in the dictionary defined above\\\n",
        "def get_images_18_32(path, age_dict):\n",
        "  images = []\n",
        "  IDs = []\n",
        "  Labels = []\n",
        "  for foldername in tqdm(os.listdir(path)):\n",
        "      if os.path.isdir(os.path.join(path,foldername)):\n",
        "        for filename in os.listdir(os.path.join(path,foldername)):\n",
        "          if filename.endswith(\".jpg\"):\n",
        "            img_ID = os.path.basename(filename)[22:]\n",
        "            if img_ID in age_dict:\n",
        "              img = load_img(os.path.join(path,foldername,filename),target_size = (224,224))\n",
        "              img = img_to_array(img)\n",
        "              img = img.reshape((1,img.shape[0],img.shape[1],img.shape[2]))\n",
        "              img = img/255\n",
        "              images.append(img)\n",
        "              IDs.append(img_ID)\n",
        "              Labels.append(age_dict[img_ID])\n",
        "              \n",
        "  \n",
        "  return(images,IDs,Labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX3XOFrICos1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "path = 'gdrive/My Drive/data/aligned/'\n",
        "Labels = []\n",
        "images = []\n",
        "IDs = []\n",
        "\n",
        "# This loads all data of people between 18 and 32 years of age\n",
        "for i in ['A','B','C','D']:\n",
        "    img, ids, label = get_images_18_32(path + i,age_dict_18_32)\n",
        "    images.extend(img)\n",
        "    IDs.extend(ids)\n",
        "    Labels.extend(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS12e3vCV69w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x2 = np.concatenate(images[:round(len(images)*(0.99))],axis = 0)\n",
        "train_y2 = utils.np_utils.to_categorical(Labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih-YCyy6WkVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x2.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcboA5yRxyQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum(train_y2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZg606CcBYdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save these files; I ran this several times to also get parts of all data to use for training/holdout etc.\n",
        "with open('gdrive/My Drive/Data/preprocessed/_18_32_All_X.txt', 'wb') as fp:\n",
        "    pickle.dump(train_x2,fp)\n",
        "  \n",
        "with open('gdrive/My Drive/Data/preprocessed/_18_32_All_y.txt', 'wb') as fp:\n",
        "    pickle.dump(train_y2,fp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8shO3TtgXlyE",
        "colab_type": "text"
      },
      "source": [
        "### I pickle dump these values so they do not need to be loaded again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkoUkEZ3Ucn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('gdrive/My Drive/Data/preprocessed/x_D.txt','wb') as fp:\n",
        "    pickle.dump(A,fp)\n",
        "    \n",
        "with open('gdrive/My Drive/Data/preprocessed/y_D.txt','wb') as fp:\n",
        "    pickle.dump(B,fp)\n",
        "\n",
        "with open('gdrive/My Drive/Data/preprocessed/val_x_D.txt','wb') as fp:\n",
        "    pickle.dump(C,fp)\n",
        "  \n",
        "with open('gdrive/My Drive/Data/preprocessed/val_y_D.txt','wb') as fp:\n",
        "    pickle.dump(D,fp)\n",
        "    \n",
        "with open('gdrive/My Drive/Data/preprocessed/own_ID_C.txt','wb') as fp:\n",
        "   pickle.dump(ID,fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0fhfn9wYz7j",
        "colab_type": "text"
      },
      "source": [
        "## Also make datasets using all data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blFHjHzXrnAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "path = 'gdrive/My Drive/data/aligned/B'\n",
        "own_x_vgg,own_y_vgg,own_v_x_vgg,own_v_y_vgg,own_ID_vgg = get_data(path,max_folders = 140,age_dict = age_dict, val_split = 0.1,vgg_processing = True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}